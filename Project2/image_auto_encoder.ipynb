{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cpay2657/CSCI602/blob/main/Project2/image_auto_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jLWM6Hu6kr99"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Flatten\n",
        "from statsmodels.sandbox.panel.sandwich_covariance_generic import kernel\n",
        "from tensorflow.keras.layers import Dense, Conv2DTranspose, Conv2D, Input, UpSampling2D, AveragePooling2D, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow.keras.preprocessing.image as image\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imsave\n",
        "import numpy as np\n",
        "import utils\n",
        "import argparse\n",
        "\n",
        "class ImageAutoEncdoderDecoder(object):\n",
        "    def __init__(self, train_config, x=None, y=None, x_test=None, y_test=None, do_val:bool=False, initialization:int=0):\n",
        "        self.initialization = initialization\n",
        "        self.model = None\n",
        "        self.reuse_pretrained_ae = train_config['reuse_pretrained']\n",
        "        self.do_val = do_val\n",
        "        self.input_shape = tuple(train_config['input_shape'])\n",
        "        self.train_decoder = train_config['train_decoder']\n",
        "        pre_train_config = train_config[\"ae_pre_train_config\"]\n",
        "        self.pre_trained_ae_path = pre_train_config[\"pre_trained_ae_path\"]\n",
        "        self.pre_batch_size = pre_train_config[\"batch_size\"]\n",
        "        self.pre_epochs = pre_train_config[\"epochs\"]\n",
        "        self.pre_patience = pre_train_config[\"patience\"]\n",
        "        pre_save_path = pre_train_config[\"ae_model_savepath\"]\n",
        "        opt_config = pre_train_config[\"optimizer\"]\n",
        "\n",
        "\n",
        "        self.input_layer = Input(shape=self.input_shape)\n",
        "\n",
        "        # If a pre-trained autoencoder path is not provided builds, compiles and trains one\n",
        "        if self.pre_trained_ae_path is None or not os.path.isfile(self.pre_trained_ae_path) or not self.reuse_pretrained_ae:\n",
        "        #if not self.pre_trained_ae_path or not self.reuse_pretrained_ae:\n",
        "            print(\"\\n\\nPretrained auto-encoder path not provided or resue False. Pretraining base auto-encoder model\")\n",
        "\n",
        "            self.model = self.build_base_ae()\n",
        "            self.compile(opt_config, self.model)\n",
        "\n",
        "            self.model = self.pre_train_ae(x, x_test, self.model)\n",
        "            if pre_save_path:\n",
        "                print('save pretrained ae model ', pre_save_path)\n",
        "                self.model.save(pre_save_path)\n",
        "            else:\n",
        "                print('ae_model_savepath empty, skipping save pretrained ae model.')\n",
        "            print(\"\\nPre-trained auto-encoder model saved: \", pre_save_path,\"\\n\")\n",
        "            self.pre_trained_ae_path = pre_save_path\n",
        "\n",
        "        else:\n",
        "            print(\"\\nLoading base auto-encoder model \", self.pre_trained_ae_path, \"\\n\")\n",
        "            self.model = load_model(self.pre_trained_ae_path)\n",
        "\n",
        "        if self.do_val:\n",
        "            self.validate(x_test, y_test, self.model, num_reconstruct=10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def build_base_ae(self):\n",
        "        if self.initialization ==0:\n",
        "            kernal_init = initializers.GlorotNormal\n",
        "        elif self.initialization==1:\n",
        "            kernal_init = initializers.HeNormal\n",
        "        elif self.initialization==2:\n",
        "            kernal_init = initializers.LecunNormal\n",
        "        elif self.initialization==3:\n",
        "            kernal_init = initializers.RandomNormal\n",
        "        elif self.initialization==4:\n",
        "            kernal_init = initializers.GlorotUniform\n",
        "        elif self.initialization==5:\n",
        "            kernal_init = initializers.RandomUniform\n",
        "\n",
        "\n",
        "        # conv = Conv2D(filters=3, kernel_size=(32,32), activation='relu', name=\"encode_1\",\n",
        "        #                  kernel_initializer=kernal_init, input_shape=self.input_shape, padding='same') (self.input_layer)\n",
        "        # conv = Conv2D(filters=2, kernel_size=(16, 16), activation='relu', name=\"encode_2\",\n",
        "        #               kernel_initializer=kernal_init, padding='same')(self.input_layer)\n",
        "        # conv = Conv2D(filters=4, kernel_size=(8, 8), activation='relu', name=\"encode_3\",\n",
        "        #               kernel_initializer=kernal_init, padding='same')(conv)\n",
        "        # conv = Conv2D(filters=8, kernel_size=(6, 6), activation='relu', name=\"encode_4\",\n",
        "        #               kernel_initializer=kernal_init, padding='same')(conv)\n",
        "        conv = Conv2D(filters=16, kernel_size=(4, 4), activation='sigmoid', name=\"encode_5\",\n",
        "                      kernel_initializer=kernal_init, padding='same')(self.input_layer)\n",
        "        conv = Conv2D(filters=32, kernel_size=(2, 2), activation='sigmoid', name=\"encode_6\",\n",
        "                      kernel_initializer=kernal_init, padding='same')(conv)\n",
        "        # conv = Conv2D(filters=8, kernel_size=(2, 2), activation='relu', name=\"encode_4\",\n",
        "        #               kernel_initializer=kernal_init)(conv)\n",
        "\n",
        "        pool = AveragePooling2D(name='encode_out')(conv)\n",
        "\n",
        "        # encoded = Flatten()(pool)\n",
        "\n",
        "\n",
        "        up_sample = UpSampling2D(size=2, name='decode_up_sample', interpolation='bilinear')(pool)\n",
        "        # dense_1 =\n",
        "\n",
        "\n",
        "        conv_t = Conv2D(filters=16, kernel_size=(2, 2), activation='sigmoid', name=\"decode_1\",\n",
        "                                  kernel_initializer=kernal_init, padding='same',)(up_sample)\n",
        "\n",
        "        decoder_out = Conv2D(filters=3, kernel_size=(4, 4), activation='sigmoid', name=\"decode_2\",\n",
        "                                  kernel_initializer=kernal_init, padding='same')(conv_t)\n",
        "        #\n",
        "        # conv_t = Conv2DTranspose(filters=8, kernel_size=(6, 6), activation='relu', name=\"decode_3\",\n",
        "        #                          kernel_initializer=kernal_init, padding='same')(conv_t)\n",
        "        #\n",
        "        # conv_t = Conv2DTranspose(filters=4, kernel_size=(8, 8), activation='relu', name=\"decode_4\",\n",
        "        #                          kernel_initializer=kernal_init, padding='same')(conv_t)\n",
        "        #\n",
        "        # decoder_out = Conv2DTranspose(filters=2, kernel_size=(16, 16), activation='relu', name=\"decode_5\",\n",
        "        #                          kernel_initializer=kernal_init, padding='same')(conv_t)\n",
        "        #\n",
        "        # # decoder_out = Conv2DTranspose(filters=3, kernel_size=(32, 32), name=\"decode_out\",\n",
        "        # #                          kernel_initializer=kernal_init, padding='same')(conv_t)\n",
        "\n",
        "        # decoder_out = LeakyReLU()(decoder_out)\n",
        "        # decoder_out = Conv2D(filters=3, kernel_size=(3, 3), activation='sigmoid', name=\"decode_out\",\n",
        "        #                      padding='same')(conv_t)\n",
        "\n",
        "        model = Model(inputs=self.input_layer,outputs=decoder_out)\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "    def compile(self, opt_config, model):\n",
        "        opt = optimizers.get(opt_config[\"identifier\"])\n",
        "        opt.learning_rate = opt_config[\"learning_rate\"]\n",
        "        model.compile(optimizer=opt, loss='binary_crossentropy', metrics='accuracy')\n",
        "\n",
        "    def pre_train_ae(self, x_train, x_test, model):\n",
        "        model.summary()\n",
        "        es = EarlyStopping('val_loss', patience=self.pre_patience, restore_best_weights=True)\n",
        "        model.fit(x_train, x_train,\n",
        "                       epochs=self.pre_epochs, batch_size=self.pre_batch_size, callbacks=[es],\n",
        "                       validation_data=(x_test, x_test))\n",
        "        return model\n",
        "\n",
        "    def load_data(self, path, input_shape):\n",
        "        \"\"\"\n",
        "                :param domain_type_return:\n",
        "                :return:\n",
        "                \"\"\"\n",
        "        print(\"loading dataset \", path)\n",
        "        image_data = []\n",
        "        class_labels = []\n",
        "\n",
        "        # Walk the domain dataset and collect the images, and the class/domain labels based on the appropriate directory\n",
        "        # name\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for file in files:\n",
        "                _, class_label = os.path.split(os.path.normpath(root))\n",
        "\n",
        "                image_path = os.path.join(root, file)\n",
        "                # Load image and convert it to an array of float\n",
        "                img = image.load_img(image_path, target_size=input_shape)\n",
        "                img_arr = image.img_to_array(img, dtype='float')\n",
        "\n",
        "                # Rescale pixel values to be between 0 and 1\n",
        "                norm_image_arr = img_arr / 255\n",
        "                image_data.append(norm_image_arr)\n",
        "                class_labels.append(class_label)\n",
        "        label_encoder = LabelBinarizer()\n",
        "        class_labels = label_encoder.fit_transform(class_labels)\n",
        "        return image_data, class_labels\n",
        "\n",
        "    def validate(self, x_test, y_test, model, num_reconstruct):\n",
        "        samples = x_test[:num_reconstruct]\n",
        "        labels = y_test[:num_reconstruct]\n",
        "\n",
        "        faux = model.predict(samples)\n",
        "        for i in np.arange(0, num_reconstruct):\n",
        "            # Get the sample and the reconstruction\n",
        "            sample = samples[i,:,:,:]\n",
        "            reconstruction = faux[0][i,:,:,:]\n",
        "            # img_real = Image.fromarray((sample*255).astype(np.uint8), 'RGB')\n",
        "            # img_fake = Image.fromarray((reconstruction*255).astype(np.uint8), 'RGB')\n",
        "            save_dir = \"/home/phat/PycharmProjects/Autoencoder_Induced_Domain_Drift/ae_sample_results\"\n",
        "            real_file_name = \"real_\" + str(10+i) + \".png\"\n",
        "            fake_file_name = \"fake_\" + str(10+i) + \".png\"\n",
        "            # img_real.save(os.path.join(save_dir, real_file_name))\n",
        "            # img_fake.save(os.path.join(save_dir, fake_file_name))\n",
        "            imsave(os.path.join(save_dir, real_file_name), sample)\n",
        "            imsave(os.path.join(save_dir, fake_file_name), reconstruction)\n",
        "            input_class = labels[i]\n",
        "            # Matplotlib preparations\n",
        "            fig, axes = plt.subplots(1, 2)\n",
        "            # Plot sample and reconstruciton\n",
        "            axes[0].imshow(sample)\n",
        "            axes[0].set_title('Original image')\n",
        "            axes[1].imshow(reconstruction)\n",
        "            axes[1].set_title('Reconstruction with Conv2DTranspose')\n",
        "            fig.suptitle(f'MNIST target = {input_class}')\n",
        "            # plt.gray()\n",
        "            plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YjB1ar5Gkr-A",
        "outputId": "3a3ceab8-4097-48aa-f9be-2a514393dda0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model_config_files/train_config_ae.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-413d61992024>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# added argv for interactivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0msource_data_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model_config_files/train_config_ae.json'"
          ]
        }
      ],
      "source": [
        "PRE_AE_PATH = \"/home/phat/PycharmProjects/Autoencoder_Induced_Domain_Drift/models/ae_augmentors/cnn_cycle_ae_wang/pretrain_ae.keras\"\n",
        "AE_MODEL_SAVEPATH=\"/home/phat/PycharmProjects/Autoencoder_Induced_Domain_Drift/models/ae_augmentors/cnn_cycle_ae_wang/pretrain_ae.keras\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Create a list of arguments to simulate command-line input\n",
        "    argv = [\n",
        "        \"--confpath\", \"model_config_files/train_config_ae.json\",\n",
        "        \"--mode\", \"test\",\n",
        "        \"--preaepath\", PRE_AE_PATH,\n",
        "        \"--aesavepath\", AE_MODEL_SAVEPATH\n",
        "    ]\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"domain drift data script .\")\n",
        "    parser.add_argument(\"--confpath\", dest=\"confpath\", type=str, default='model_config_files/train_config_ae.json')\n",
        "    parser.add_argument(\"--mode\", dest=\"mode\", type=str, default='test')\n",
        "    parser.add_argument(\"--preaepath\", dest=\"preaepath\", type=str, default=PRE_AE_PATH)\n",
        "    parser.add_argument(\"--aesavepath\", dest=\"aemodelsavepath\", type=str, default=AE_MODEL_SAVEPATH)\n",
        "    args = parser.parse_args(argv) # added argv for interactivity\n",
        "\n",
        "    f=open(args.confpath)\n",
        "    train_config = json.load(f)\n",
        "    source_data_path= train_config['source']\n",
        "\n",
        "    src_images, src_labels = utils.load_data(data_path=source_data_path, input_shape=train_config['input_shape'])\n",
        "    x_train, y_train, x_test, y_test = utils.preprocess_data(src_images, src_labels)\n",
        "    generator = ImageAutoEncdoderDecoder(train_config, x_train, y_train, x_test, y_test, initialization=1)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}